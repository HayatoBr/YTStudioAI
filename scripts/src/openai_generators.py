# scripts/src/openai_generators.py
from __future__ import annotations

import json
import os
import re
import time
from typing import Any, Dict, List, Optional, Union

from openai import OpenAI

# OpenAI client reads OPENAI_API_KEY from environment by default
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"), timeout=float(os.getenv("AO_OPENAI_TIMEOUT", "120")))


def _chat_completion_with_retry(*, model: str, messages: List[Dict[str, str]], temperature: float, max_retries: int = 3) -> str:
    """Wrapper com timeout e retries (rede inst√°vel / travas).
    Retorna content string (pode ser vazia). Lan√ßa exce√ß√£o ap√≥s esgotar tentativas.
    """
    backoff = float(os.getenv("AO_OPENAI_RETRY_BACKOFF", "2.0"))
    for attempt in range(1, max_retries + 1):
        try:
            t0 = time.time()
            if attempt > 1:
                print(f"üîÅ Re-tentando OpenAI ({attempt}/{max_retries})...")
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
            )
            dt = time.time() - t0
            if dt > 5:
                print(f"‚úÖ OpenAI respondeu em {dt:.1f}s")
            return (resp.choices[0].message.content or "").strip()
        except Exception as e:
            # Mostra erro curto e tenta novamente
            print(f"‚ö†Ô∏è OpenAI falhou (tentativa {attempt}/{max_retries}): {type(e).__name__}: {e}")
            if attempt >= max_retries:
                raise
            time.sleep(backoff * attempt)
    return ""


def _extract_json_candidate(text: str) -> Optional[str]:
    """
    Extract a plausible JSON object from a model response that may include extra text.
    Returns the JSON string if found, else None.
    """
    if not text:
        return None
    s = text.strip()

    # Fast path: looks like pure JSON
    if s.startswith("{") and s.endswith("}"):
        return s

    # Remove fenced code blocks if any
    s = re.sub(r"^```(?:json)?\s*", "", s, flags=re.IGNORECASE).strip()
    s = re.sub(r"\s*```$", "", s).strip()

    # Best-effort: take outermost braces
    start = s.find("{")
    end = s.rfind("}")
    if start != -1 and end != -1 and end > start:
        return s[start : end + 1]

    return None


def _safe_json_loads(text: str) -> Optional[Dict[str, Any]]:
    cand = _extract_json_candidate(text)
    if not cand:
        return None
    try:
        obj = json.loads(cand)
        return obj if isinstance(obj, dict) else None
    except Exception:
        return None


def _default_scenes() -> List[Dict[str, Any]]:
    # 7 cenas padr√£o ‚ÄúArquivo Oculto‚Äù
    anchors = [
        "arquivo confidencial com carimbo",
        "corredor escuro com l√¢mpada falhando",
        "mapa com rota marcada em vermelho",
        "foto rasgada em cima da mesa",
        "c√¢mera de seguran√ßa granulado",
        "recorte de jornal antigo",
        "silhueta ao fundo na chuva",
    ]
    cameras = ["close", "wide", "medium", "close", "medium", "close", "wide"]
    return [{"visual_anchor": a, "camera": c} for a, c in zip(anchors, cameras)]


def _normalize_script_dict(d: Dict[str, Any], raw_fallback: str = "") -> Dict[str, Any]:
    title = d.get("title")
    narration = d.get("narration")
    scenes = d.get("scenes")

    if not isinstance(title, str) or not title.strip():
        d["title"] = "Arquivo Oculto (auto)"

    if not isinstance(narration, str):
        # fallback to raw text if model didn't comply
        d["narration"] = str(raw_fallback or "").strip()

    # Remove any legacy placeholders that should NEVER reach subtitles
    # (your subtitle_from_script now strips/ignores these, but we keep it clean here too)
    d["narration"] = re.sub(r"\[PAUSA_FINAL\]\s*$", "", d["narration"].strip(), flags=re.MULTILINE).strip()

    # Scenes: keep for visual system; subtitles are generated from narration elsewhere
    if not isinstance(scenes, list):
        scenes = []
    scenes_clean: List[Dict[str, Any]] = []
    for s in scenes:
        if not isinstance(s, dict):
            continue
        va = s.get("visual_anchor")
        cam = s.get("camera")
        item = {
            "visual_anchor": va if isinstance(va, str) and va.strip() else "arquivo",
            "camera": cam if cam in ("wide", "medium", "close") else "medium",
        }
        # Preserve extra keys if you use them later (e.g., mood, negative_prompt)
        for k, v in s.items():
            if k in item:
                continue
            item[k] = v
        scenes_clean.append(item)

    # Ensure exactly 7 scenes
    if len(scenes_clean) < 7:
        padding = _default_scenes()
        # fill remaining with defaults
        for i in range(len(scenes_clean), 7):
            scenes_clean.append(padding[i])
    elif len(scenes_clean) > 7:
        scenes_clean = scenes_clean[:7]

    d["scenes"] = scenes_clean

    # Optional field: final_question
    fq = d.get("final_question")
    if fq is not None and not isinstance(fq, str):
        d["final_question"] = str(fq)

    return d


def _repair_to_json(model: str, bad_output: str) -> str:
    """
    Second-pass repair: ask the model to output valid JSON only.
    Keep temperature low to maximize compliance.
    """
    repair_prompt = (
        "Converta o conte√∫do abaixo em APENAS um JSON v√°lido (sem markdown, sem texto extra), "
        "seguindo este schema:\n"
        "{\n"
        '  "title": "string",\n'
        '  "narration": "string",\n'
        '  "scenes": [ { "visual_anchor": "string", "camera": "wide|medium|close" } x7 ],\n'
        '  "final_question": "string (opcional)"\n'
        "}\n\n"
        "Conte√∫do:\n"
        + bad_output
    )
    return _chat_completion_with_retry(model=model, messages=[
            {"role": "system", "content": "Voc√™ √© um conversor rigoroso para JSON v√°lido."},
            {"role": "user", "content": repair_prompt},
        ], temperature=0.1, max_retries=int(os.getenv("AO_OPENAI_RETRY", "3")))


def generate_short_script() -> Dict[str, Any]:
    """
    Gera roteiro curto para o canal Arquivo Oculto.
    CONTRATO: sempre retorna um dict v√°lido (nunca string).
    """
    model = os.getenv("AO_SCRIPT_MODEL", "gpt-4.1-mini")

    # Prompt cinematogr√°fico + investigativo (TikTok pacing), sem placeholders de "pausa final"
    prompt = (
        "Voc√™ √© roteirista investigativo cinematogr√°fico. Escreva para TTS (fala natural).\n"
        "Canal: Arquivo Oculto. Est√©tica dark/documental.\n\n"
        "Objetivo: um SHORT de 45‚Äì60s em PT-BR, ritmo alto, frases curtas e visuais.\n"
        "Restri√ß√µes: n√£o use nomes reais, n√£o acuse pessoas reais; evite gore expl√≠cito.\n\n"
        "Regras obrigat√≥rias de qualidade:\n"
        "1) Narra√ß√£o entre 130 e 160 palavras.\n"
        "2) Inclua 3 evid√™ncias concretas (sem nomes):\n"
        "   - um hor√°rio ou data aproximada (ex: 'por volta das 2h', 'no fim de 2001')\n"
        "   - um local gen√©rico verific√°vel (ex: 'esta√ß√£o', 'arquivo municipal', 'rodovia')\n"
        "   - um detalhe f√≠sico (ex: 'carimbo CONFIDENCIAL', 'foto rasgada', 'fita')\n"
        "3) Traga 1 contradi√ß√£o espec√≠fica (algo que n√£o bate).\n"
        "4) Use retic√™ncias '‚Ä¶' apenas quando mudar de ideia (poucas vezes).\n"
        "5) Final: 2 linhas curtas:\n"
        "   - Linha 1: frase curta (m√°x 6 palavras), com ponto.\n"
        "   - Linha 2: pergunta curta (m√°x 10 palavras), com interroga√ß√£o.\n\n"
        "Estrutura sugerida:\n"
        "- 0‚Äì3s: gancho com dado concreto\n"
        "- 3‚Äì12s: contexto r√°pido\n"
        "- 12‚Äì40s: 3 evid√™ncias (1 por bloco)\n"
        "- 40‚Äì52s: contradi√ß√£o e hip√≥tese\n"
        "- 52‚Äì60s: fechamento + pergunta\n\n"
        "Sa√≠da: retorne APENAS um JSON v√°lido (sem markdown), exatamente neste formato:\n"
        "{\n"
        '  "title": "‚Ä¶",\n'
        '  "narration": "texto com quebras de linha\\n(2 linhas finais separadas)",\n'
        '  "scenes": [\n'
        '    {"visual_anchor": "‚Ä¶", "camera": "wide|medium|close"},\n'
        "    ... (exatamente 7 itens)\n"
        "  ],\n"
        '  "final_question": "a mesma pergunta da narra√ß√£o"\n'
        "}\n"
    )

    raw = _chat_completion_with_retry(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "Voc√™ cria roteiros investigativos curtos com evid√™ncias concretas e ritmo cinematogr√°fico.",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=float(os.getenv("AO_SCRIPT_TEMPERATURE", "0.8")),
        max_retries=int(os.getenv("AO_OPENAI_RETRY", "3")),
    )

    data = _safe_json_loads(raw)

    # One repair attempt if invalid
    if data is None:
        repaired = _repair_to_json(model=model, bad_output=raw)
        data = _safe_json_loads(repaired)

    if data is None:
        # Hard fallback: return dict anyway
        data = {
            "title": "Arquivo Oculto (auto)",
            "narration": raw,
            "scenes": _default_scenes(),
        }

    return _normalize_script_dict(data, raw_fallback=raw)


# =========================
# LONGS (5‚Äì8 min) ‚Äî Arquivo Oculto
# =========================

def _get_long_theme() -> str:
    """Tema editorial do LONG definido por ENV (controla o tipo de caso)."""
    theme = os.getenv("AO_LONG_THEME", "casos_frios").strip().lower()
    aliases = {
        "desaparecimento": "desaparecimentos",
        "desaparecimentos": "desaparecimentos",
        "caso_frio": "casos_frios",
        "casos_frios": "casos_frios",
        "arquivos": "arquivos_militares",
        "arquivos_militares": "arquivos_militares",
        "historico": "eventos_historicos_controversos",
        "eventos_historicos": "eventos_historicos_controversos",
        "eventos_historicos_controversos": "eventos_historicos_controversos",
        "catastrofes": "catastrofes_misteriosas",
        "catastrofes_misteriosas": "catastrofes_misteriosas",
    }
    return aliases.get(theme, theme)


def _normalize_long_dict(d: Dict[str, Any], scenes_count: int) -> Dict[str, Any]:
    if not isinstance(d, dict):
        d = {}

    d.setdefault("title", "Arquivo Oculto: Caso em Aberto")
    d.setdefault("summary", "")
    d.setdefault("narration", "")
    d.setdefault("thumbnail_prompt", "")

    # structure
    st = d.get("structure")
    if not isinstance(st, dict):
        st = {}
    st.setdefault("opening_hook", "")
    st.setdefault("official_version", "")
    st.setdefault("timeline_blocks", [])
    st.setdefault("contradictions", [])
    st.setdefault("hypotheses", [])
    st.setdefault("closing_statement", "")

    # normalize arrays
    if not isinstance(st["timeline_blocks"], list):
        st["timeline_blocks"] = []
    if not isinstance(st["contradictions"], list):
        st["contradictions"] = []
    if not isinstance(st["hypotheses"], list):
        st["hypotheses"] = []

    d["structure"] = st

    scenes = d.get("scenes")
    if not isinstance(scenes, list):
        scenes = []

    # clean each scene
    clean = []
    for s in scenes:
        if not isinstance(s, dict):
            continue
        clean.append(
            {
                "visual_anchor": str(s.get("visual_anchor") or "").strip()[:60] or "arquivo antigo",
                "location": str(s.get("location") or "").strip()[:60] or "arquivo municipal",
                "era": str(s.get("era") or "").strip()[:30] or "anos 2000",
                "object_focus": str(s.get("object_focus") or "").strip()[:60] or "pasta carimbada",
                "camera": (str(s.get("camera") or "wide").strip().lower() if str(s.get("camera") or "") else "wide"),
                "mood": (str(s.get("mood") or "archival").strip().lower() if str(s.get("mood") or "") else "archival"),
            }
        )

    # clamp camera/mood
    for s in clean:
        if s["camera"] not in ("wide", "medium", "close"):
            s["camera"] = "wide"
        if s["mood"] not in ("dark", "neutral", "cold", "archival"):
            s["mood"] = "archival"

    # enforce count
    if len(clean) > scenes_count:
        clean = clean[:scenes_count]
    while len(clean) < scenes_count:
        clean.append(
            {
                "visual_anchor": "arquivo antigo",
                "location": "arquivo municipal",
                "era": "anos 2000",
                "object_focus": "pasta carimbada",
                "camera": "close" if (len(clean) % 3 == 0) else "wide",
                "mood": "archival",
            }
        )

    d["scenes"] = clean
    return d


def _repair_long_to_json(model: str, bad_output: str, scenes_count: int) -> str:
    """Second-pass repair para LONG: for√ßa JSON puro no schema do LONG."""
    repair_prompt = (
        "Converta o conte√∫do abaixo em APENAS um JSON v√°lido (sem markdown, sem texto extra), "
        "seguindo este schema:\\n"
        "{\\n"
        '  "title": "string",\\n'
        '  "summary": "string",\\n'
        '  "narration": "string",\\n'
        '  "structure": {\\n'
        '    "opening_hook": "string",\\n'
        '    "official_version": "string",\\n'
        '    "timeline_blocks": [ {"label":"string","description":"string","approx_time_reference":"string"} ],\\n'
        '    "contradictions": [ {"official_claim":"string","conflicting_record":"string"} ],\\n'
        '    "hypotheses": ["string"],\\n'
        '    "closing_statement": "string"\\n'
        "  },\\n"
        f'  "scenes": [ {{"visual_anchor":"string","location":"string","era":"string","object_focus":"string","camera":"wide|medium|close","mood":"dark|neutral|cold|archival"}} x{scenes_count} ],\\n'
        '  "thumbnail_prompt": "string"\\n'
        "}\\n\\n"
        "Conte√∫do:\\n"
        + bad_output
    )
    return _chat_completion_with_retry(model=model, messages=[
            {"role": "system", "content": "Voc√™ √© um reparador de JSON. Retorne somente JSON v√°lido."},
            {"role": "user", "content": repair_prompt},
        ], temperature=0.0, max_retries=int(os.getenv("AO_OPENAI_RETRY", "3")))


def generate_long_script() -> Dict[str, Any]:
    """
    Gera roteiro LONG (5‚Äì8 min) para o canal Arquivo Oculto.
    A IA escolhe um caso real dentro do nicho definido por AO_LONG_THEME.
    CONTRATO: sempre retorna um dict v√°lido (nunca string).
    """
    model = os.getenv("AO_LONG_MODEL", os.getenv("AO_SCRIPT_MODEL", "gpt-4.1-mini"))
    theme = _get_long_theme()

    # dura√ß√£o/escopo
    try:
        minutes = float(os.getenv("AO_LONG_MINUTES", "6.5"))
    except Exception:
        minutes = 6.5
    minutes = max(4.5, min(10.0, minutes))

    try:
        scenes_count = int(os.getenv("AO_LONG_SCENES", "14"))
    except Exception:
        scenes_count = 14
    scenes_count = max(12, min(18, scenes_count))

    # fechamento (IA escolhe 1)
    closings = [
        "Os registros permanecem abertos.",
        "O arquivo segue incompleto.",
        "Nem todos os documentos vieram √† tona.",
        "Algumas respostas continuam ausentes.",
        "O caso permanece encerrado. Nos arquivos, n√£o.",
    ]

    theme_guidance = {
        "desaparecimentos": "desaparecimento documentado, com linha do tempo e √∫ltimas evid√™ncias (c√¢meras, bilhetes, registros de transporte).",
        "casos_frios": "caso n√£o resolvido com evid√™ncias materiais e contradi√ß√µes em relat√≥rios/declara√ß√µes oficiais.",
        "arquivos_militares": "documentos/arquivos institucionais, memorandos, registros desclassificados (sem citar nomes completos).",
        "eventos_historicos_controversos": "evento hist√≥rico com vers√µes conflitantes e documenta√ß√£o incompleta.",
        "catastrofes_misteriosas": "incidente/cat√°strofe com falhas documentais e inconsist√™ncias t√©cnicas (registros, relat√≥rios).",
    }.get(theme, "caso investigativo documental com documenta√ß√£o incompleta e contradi√ß√µes.")

    # palavras alvo (fala)
    min_words = int(max(750, minutes * 130))
    max_words = int(max(950, minutes * 170))

    prompt = (
        "Voc√™ √© roteirista investigativo cinematogr√°fico (Arquivo Oculto). Escreva para TTS (fala natural, PT-BR).\\n"
        "Tom: neutro, preciso, documental. Sem sensacionalismo. Sem acusar indiv√≠duos reais.\\n"
        f"Tema editorial (AO_LONG_THEME): {theme} ‚Äî {theme_guidance}\\n\\n"
        "Escolha um caso REAL amplamente conhecido/documentado (Brasil ou mundo), mas:\\n"
        "- N√£o use nomes completos de pessoas reais. Se mencionar, use iniciais ou descri√ß√µes gen√©ricas.\\n"
        "- Se houver risco de imprecis√£o, trate datas como aproximadas e use linguagem: 'registros p√∫blicos indicam', 'relat√≥rios apontam'.\\n"
        "- Use elementos documentais plaus√≠veis: datas, hor√°rios, locais gen√©ricos verific√°veis, n√∫meros de protocolo fict√≠cios, carimbos e transcri√ß√µes curtas.\\n\\n"
        f"Meta: {minutes} minutos (faixa de {min_words} a {max_words} palavras).\\n"
        "Estrutura obrigat√≥ria (n√£o escreva r√≥tulos):\\n"
        "1) Abertura fria (20‚Äì40s) com detalhe f√≠sico + hor√°rio/data e tens√£o documental.\\n"
        "2) Contexto documentado (onde/quando/vers√£o oficial).\\n"
        "3) Linha do tempo em 4 a 6 blocos, cada um com: evento + evid√™ncia concreta + local.\\n"
        "4) Contradi√ß√£o central: vers√£o oficial vs registro conflitante (espec√≠fico).\\n"
        "5) Hip√≥teses plaus√≠veis (2‚Äì3), sem afirmar conclus√µes.\\n"
        "6) Encerramento com assinatura (a IA escolhe uma varia√ß√£o).\\n\\n"
        "Coer√™ncia visual (muito importante):\\n"
        "- Tudo deve ser ger√°vel em imagem documental (arquivo, papel, mapa, pr√©dio, estrada, fita, foto, carimbo).\\n"
        "- Evite elementos abstratos.\\n\\n"
        f"Cenas: gere exatamente {scenes_count} cenas.\\n"
        "- visual_anchor: 2‚Äì6 palavras, sempre concreto.\\n"
        "- location: curto e espec√≠fico.\\n"
        "- era: ano ou d√©cada aproximada.\\n"
        "- object_focus: objeto principal.\\n"
        "- camera: wide|medium|close.\\n"
        "- mood: dark|neutral|cold|archival.\\n\\n"
        "Sa√≠da: retorne APENAS JSON v√°lido (sem markdown) neste formato:\\n"
        "{\\n"
        '  "title": "‚Ä¶",\\n'
        '  "summary": "‚Ä¶",\\n'
        '  "narration": "‚Ä¶",\\n'
        '  "structure": {\\n'
        '    "opening_hook": "‚Ä¶",\\n'
        '    "official_version": "‚Ä¶",\\n'
        '    "timeline_blocks": [{"label":"‚Ä¶","description":"‚Ä¶","approx_time_reference":"‚Ä¶"}],\\n'
        '    "contradictions": [{"official_claim":"‚Ä¶","conflicting_record":"‚Ä¶"}],\\n'
        '    "hypotheses": ["‚Ä¶"],\\n'
        '    "closing_statement": "‚Ä¶"\\n'
        "  },\\n"
        '  "scenes": [{"visual_anchor":"‚Ä¶","location":"‚Ä¶","era":"‚Ä¶","object_focus":"‚Ä¶","camera":"wide|medium|close","mood":"dark|neutral|cold|archival"}],\\n'
        '  "thumbnail_prompt": "‚Ä¶"\\n'
        "}\\n\\n"
        "Escolha UMA assinatura dentre estas op√ß√µes (pode adaptar levemente):\\n"
        + "\\n".join([f"- {c}" for c in closings])
        + "\\n"
        "Regras finais: JSON puro; n√£o inclua 'pausa final' nem '...'.\\n"
    )

    raw = _chat_completion_with_retry(
        model=model,
        messages=[
            {"role": "system", "content": "Voc√™ cria roteiros LONG (PT-BR) com est√©tica documental e tom neutro. Responda sempre em JSON puro."},
            {"role": "user", "content": prompt},
        ],
        temperature=float(os.getenv("AO_LONG_TEMPERATURE", "0.8")),
        max_retries=int(os.getenv("AO_OPENAI_RETRY", "3")),
    )
    data = _safe_json_loads(raw)

    if not isinstance(data, dict):
        fixed = _repair_long_to_json(model, raw, scenes_count=scenes_count)
        data = _safe_json_loads(fixed)

    data = _normalize_long_dict(data if isinstance(data, dict) else {}, scenes_count=scenes_count)

    # garante assinatura se vazia
    st = data.get("structure") or {}
    if isinstance(st, dict):
        if not str(st.get("closing_statement") or "").strip():
            st["closing_statement"] = closings[0]
        data["structure"] = st

    return data
